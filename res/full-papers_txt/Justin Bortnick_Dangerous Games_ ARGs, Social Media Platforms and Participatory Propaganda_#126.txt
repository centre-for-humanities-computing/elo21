Abstract: Video games and their associated forms stand as the most lucrative entertainment 
sector on the planet, dominating other forms of visual media in dollars generated annually.  In 
the proposed paper, adapted from a dissertation chapter, I will draw upon my experience as a 
game designer to illuminate the increasingly dire ways that various actors in the political sphere 
– from online trolls all the way to world leaders – have combined the language and techniques 
borne from the industrial practices of game design with the power of social media and other 
online communication platforms to produce new forms of disinformation, propaganda and 
conspiracy theory.  In this paper, I will trace the history of a specific form of game – the 
Alternate Reality Game (ARG), from its early literary history in 1903 to its modern incarnations.  
Subsequently, by harnessing lessons from my own work developing ARGs for both video game 
and film productions, I will examine how closely the principles employed during ARG 
marketing campaign have been in similar use in American politics since the 2016 American 
presidential campaign, culminating in the January 6, 2021 attack on the US Capital.  I will 
discuss how modern totalitarian systems will almost certainly continue to refine and deploy these 
strategies in the future as a new, dangerous form of propaganda: one that lives primarily in 
online discussion platforms and, much like the narrative of an ARG, is constructed both 
unwittingly and collaboratively by the targets of the propaganda themselves.  Finally, I utilize 
my experience both as a designer and online community manager to address how, especially 
during COVID-19 quarantine, these emerging risks can be combatted as the daily intersection of 
digital and analogue worlds continue to merge ever closer. 

 
 

Dangerous Games: ARGs, Social Media Platforms and Participatory Propaganda 

 

Alternate Reality Games, or ARGs, are a form of entertainment that combine traditional 

game design, narrative storytelling, broad-scale social interaction and the temporality of a live event.  

They often straddle the line between a serious attempt at interactive narrative and a commercial 

marketing effort, being deployed not for their own sake but instead with the goal of boosting the 

market presence of another project.  ARGs ask their players to willingly suspend their disbelief and 

step into a game world that overlays the real one – an alternate reality where fictionalized events take 

place.  The ARG’s design principles, which allow for thousands, or even millions, of simultaneous 

players, have broken free of their previously-constrained place in the world of entertainment and 

begun to echo across the modern geopolitical landscape.  Observing the real-world application of 

these principles provides an answer to the question, “How can a political actor both effectively 

communicate to a large population and also convince an audience to believe and participate in a 

specific, preconstructed version of reality?”  As a form already largely streamlined for marketing 

efforts, the ARG presents an off-the-shelf solution for groups looking to propagate a message.  In this 

paper, I will touch on the history of the ARG as a form, briefly describe my own experience 

designing commercial ARGs, and highlight how malicious political actors are already using tools 

birthed from industrial game design to disseminate new forms of propaganda and political speech. 

The concept of an alternate reality game was presaged in the short story “The Tremendous 

Adventures of Major Brown,” published in 1903 by G. K. Chesterton in Harper’s Weekly.  Over the 

course of the story, the retired Major Brown becomes an unwilling participant in what would be, by 

modern standards, a custom-tailored ARG.  Actors approach him with 

information, he is given confusing messages, encounters bizarre 

phenomena (for example, a bed of pansies spells out the message 

“Death to Major Brown”), is assaulted by a mysterious figure, and is 

sent on a small-scale adventure to track down the source of the 

conspiracy.  Upon doing so, he learns that this has all been done by the 

Adventure and Romance Agency, Limited.  The puppet masters running 

the Agency have accidentally targeted the Major with their game, 

which was commissioned on behalf of the prior resident of his home.1  

Even in this nascent form, this proto-ARG story was acting as a tool 

for commercial promotion: though the tale runs only four pages in 

Page 2 of Major Brown in 
Harpers, illustrating the 
space allocation between 
the story (left column) and 
advertisements. 

Harper’s, nearly half of that space is dedicated to advertisements for hotels, bread machines, 

cigarettes, automobiles and other goods and services.  Since their earliest theoretical conception, as 

we can see, ARGs have been inextricably linked to the idea of a marketplace.  Even were one to read 

                                                 
1 Additional writing on ARGs and Major Brown can be found in Bryan Alexander’s white paper  “Antecedents to 
Alternate Reality Games,” published in 2006 by The International Game Developers Association’s Alternate Reality 
Games Special Interest Group. 

Chesterton’s story in anthology, divorced from the advertisements that surrounded its initial 

publication, one would find market forces to be present in the work itself: Major Brown, upon 

confronting his tormentors, is presented with a bill tallying the expenses for the adventure he was 

provided.  In other words, the ARG has always been transactional.  My own experience designing 

ARGs has exposed to me the thin line between what we think of as “play” and what are aggressive 

sales techniques, though what is being sold is not always a durable good and can often be a 

philosophy or set of ideas.   

The first modern proto-ARG was a piece of outsider art called Ong’s Hat, conceived circa 

1987.  After gaining popularity online in the 1990s, the form was quickly imitated for commercial 

purposes.  In the words of its creator, Joe Matheny, “I saw Hollywood grab the ARG thing and just 

basically prostitute[d] it out to be a vehicle for marketing” (Matheny).  Matheny was referencing 

the first mainstream marketing ARG, which debuted in 2001, nearly a century after Chesterton 

published Major Brown. That year, Microsoft launched The Beast, an ARG created to promote the 

release of Stephen Spielberg’s film AI: Artificial Intelligence, and with that launch, the modern 

commercial ARG was born.  Using clues hidden in the film’s trailers, print marketing, posters and 

other promotional material; a vast network of story and puzzle content in the form of writing, video, 

interactive games and more, was strewn across dozens of websites.  Sean Stewart, head writer on the 

project, wrote of a design philosophy which looked to dominate every platform:  

“[the] idea was that we would tell a story that was not bound by communication platform: 

it would come at you over the web, by email, via fax and phone and billboard and TV and 

newspaper, SMS and skywriting and smoke signals too if we could figure out how. The 

story would be fundamentally interactive, made of little bits that players, like detectives 

or archaeologists, would discover and fit together. We would use political pamphlets, 

business brochures, answering phone messages, surveillance camera video, stolen diary 

pages… 

Anybody who noticed these connections could experience a story that tied to that of the film and 

appeared to be actually happening in the “real world” despite being clearly fictional – thus creating 

an alternate reality.  To unravel the secrets of The Beast required the collaboration of thousands of 

players who had never experienced anything like it.  At the peak of its activity, a discussion list 

dedicated to the game was generating tens of thousands of messages each week (Manjoo).   

 

Other subsequent successful mainstream ARGs follow a similar model: with the goal of 

marketing a film or product, a designer will plant clues that first seed a broader storyline and then 

build a community of puzzle-solvers that will, in theory, both consume the product and serve as a 

viral marketing team, promoting the game to friends and across the broader internet as the player 

community attempts to recruit ever more people to help solve the ARG’s puzzles.2   

This is not to say that ARGs are solely the realm of the corporate marketing department.  

Artist collective Synydyne’s performance art ARG This is My Milwaukee (2008-2009) or Jeff 

Hull’s San Fransisco based Jejune Institute (2008) are two prominent examples of 

noncommercial projects, with the story of the latter inspiring a television show for AMC in 

March 2020.  ARGs have also been used for education and research.  The 2007 game World 

Without Oil, from a team headed by Ken Eklund, sought to explore a future reeling from a 

sudden shortage of oil and was funded by the Corporation for Public Broadcasting, while Patrick 

Jagoda and a team produced The Source to study ARGs as a scalable learning platform.  

However, non-commercial ARGs tend to be outliers; the vast majority of large-scale projects are 

created for product promotion.  As author and ARG designer Maureen McHugh told me, “most 

                                                 
2 This didn’t work so well for The Beast, as AI: Artificial Intelligence failed to make back its budget at the box office 
despite the popularity of the ARG. 

ARGs are expensive to produce, and the only funding available, unless you get an art grant, is to find 

somebody who thinks they can use it as content marketing.” 

 

  In 2019, I was asked to work on a new ARG for the company Definitely Real.  The 

company was pursuing a film project called Dared My Best Friend (“Dared”), which was described 

as “Alternate Reality Cinema.”  Instead of drawing upon the more traditional film/ARG model 

pioneered by The Beast, where two projects ran in parallel, connected by plot and thematic details, 

Definitely Real’s film looked not only to tie the narratives of the film project to an ARG, but also to a 

network of thirty to fifty other collaborators, who produced related but distinct art and media projects 

across the internet that spoke to the themes and ideas of the film.  The distribution of the film was 

also novel: instead of being distributed by a major studio or even released all at once, it aired 

episodically online, with each episode releasing in real-time over online streaming services such as 

YouTube.  When a new episode launched, the amount of time that had elapsed in the story was the 

same amount of time that had passed in the real world since the release of the previous episode, 

giving the appearance that the events of the film were actually happening. 

 

The plot of Dared is straightforward.  Two best friends, Zander and David, are bored during 

summer vacation and dare one other to ruin each other’s life as a way of keeping themselves alert 

and sharp.  The dare escalates far beyond the bounds of good sense, and both characters are thrust 

into a dark world of computer hacking, modern technological social manipulation, and eventually 

death.  From the project’s outset, one of its goals was to serve as not only entertainment but also as 

an educational service which instructs and informs the viewer-players about internet safety and 

security in the 21st century.  To facilitate this goal, over the course of the narrative the Zander forms 

an online “team” for support and assistance.  Zander then issues missions to his team, with the goals 

shifting in tone and escalating in severity in the face of David’s repeated attempts to ruin his life.  

What begins as an attempt at self preservation transforms into revenge after Zander’s sister is 

kidnapped.  The content of missions ranging from asking users to access websites only available via 

the TOR browser to infiltrating fictional web forums for “Team Takedown,” an antagonistic online 

community of disaffected angry people, mostly men, with whom the protagonist’s friend had allied 

himself, and whose members vaguely resembled people who had participated in the online hate 

movement, Gamergate, in 2014.3 

 

As Dared demonstrates, the production and dissemination of fictional content in the service 

of an entertainment product closely mirrors techniques and strategies used by disinformation 

campaigns.  Much as Russian troll farms were used to impersonate Americans and sew division in 

the lead-up to the 2016 presidential election, Dared hired multiple actors to play fictional characters 

online, maintaining their social profiles and interacting with players as if they were real people 

caught up in the thrill of the ARG.  With only slight tweaks to the formula, a skilled disinformation 

department could disseminate political propaganda to befuddle the masses.  Unlike traditional 

propaganda, where disinformation flows from the top down – in other words, from a government to 

its citizenry (or to whomever the target is) – the new age of propaganda is largely bottom-out.  

Although the information may still originate with a government or other powerful organization, it is 

primarily distributed by the targets to each other.   

This new paradigm is what Alicia Wanless and Michael Berk call “participatory 

propaganda.”  “Participatory propaganda,” they explain, “moves beyond a traditional, unidirectional 

‘one-to-many’ form of communication, to a ‘one-to-many-to-many more’ form” (Berk and Wanless, 

6).  They continue by explaining that under this system, the target(s) of propaganda can themselves 

double as spreaders of propaganda, producing new content that expands the reach of the original 

                                                 
3 More information about this project can be found at the website of the production studio: 
http://www.definitelyreal.com 

message to new audiences in what they describe as a snowball effect.  Because the message is 

designed to resonate with preexisting dispositions of the targets, targets are incentivized to share and 

spread the message.  This technique was on full display in the 2016 American presidential election as 

part of Donald Trump’s “Great Meme War.” Alex Gekker explains that “[t]his semi-facetious term, 

which references bloody conflicts of old yet is filled with purposefully self-deprecating humor, was 

favored by online supporters of Trump, claiming to have ‘actually elected a meme as a president’” – 

one only need look at images of cartoon character Pepe the Frog, a character often drawn by right-

wing internet users to resemble Trump, for a visual example of this way of thinking (Gekker, 400).  

In pointing out that “the main conceptual innovation of Trump’s campaign was utilizing micro-

volunteering for cultural meaning-making,” Gekker cuts to the heart of this new technique for 

disseminating political messages: with very little effort, one can catalyze one’s audience to 

proselytize, amplifying one’s statements and expanding the scope of one’s reach far beyond the 

audiences available using traditional propaganda.  There is also no reason to fear that the message 

will become lost or distorted as it moves through the hands of others: “Even if modified through the 

consumer’s own interpretation, the core message remains intact, and sometimes [can] even acquire a 

‘new life’ (e.g. a new wave of content dissemination)” (Berk and Wanless, 6). 

 

The new methodology of spreading propaganda imbues any information disseminated in this 

way with a deeper level of danger, as it circumvents one of the major hurdles that propaganda has 

historically been forced to overcome.  Hannah Arendt writes, “Since totalitarian movements exist in 

a world which itself is nontotalitarian, they are forced to resort to what we commonly regard as 

propaganda.  But such propaganda always makes its appeal to an external sphere – be it the 

nontotalitarian strata of the population at home or the nontotalitarian countries abroad. […] The 

external sphere can also be represented by groups of sympathizers who are not yet ready to accept the 

true aims of the movement…” (342-343).  Conquering this external sphere has always been the 

major challenge for totalitarian movements, yet participatory propaganda allows those who utilize it 

successfully to sidestep the obstacle. This is because the propaganda appears to originate from within 

the external sphere, as shared by members of that external sphere, for their own in-group 

consumption.  It takes only a single individual in the external sphere to adopt the message and share 

it with friends and family for that message to become integrated into that selfsame sphere.  As there 

is no sense of an outside government or power attempting to impose ideas from an outside position, 

there is less suspicion from members of the sphere in question.  The internet has provided plenty of 

external spheres ripe for infiltration due to the public-yet-insular nature of online communities; 

anyone can join, but each communy has its own micro-power structures, influencers, and social 

dynamics.   

Like participants in many other enthusiast cultures, gamers have been forming online 

communities for decades.  What differentiates gaming communities from many others types of fan 

communities is that the content of many modern titles has inadvertently conditioned game players to 

be receptive to messages promoting violence, hatred, and other negative mindsets.  Hate groups have 

long been aware of the power of games to propagandize for their causes.  Michael S. Waltman 

writes:  

Online games “allow the hate monger to conquer the out-group rhetorically.  Many online 

games position the player to take the point of view of a shooter or bomber and accumulate 

points by killing members of the out-group.  The game, Watch Out Behind You, Hunter, 

allows the game player to conquer gay men symbolically by hunting and killing gay rapists” 

(97-98). 

These sorts of hate-games present as propaganda, perhaps at times even as satire due to their 

grotesque and over-the-top content, but as Waltman notes, “Arguably, when players repeat these 

games time after time, they may eventually see themselves killing their enemies in real life.” 

Whether the consumption of violence in video games can be linked to real-world violent acts 

continues to be a controversial subject.  The American Psychological Association notes that, while 

video games may lead to aggression, not all aggression is violent, and that, especially when taken 

within the context of the broader cultural fractures in modern American society, presenting hateful 

content as a form of entertainment can have the effect of normalizing the beliefs. 

 

It is not hard to draw the line between my own work and the participatory propaganda model.  

Much of my work on ARGs has taken place on social media platforms such as Twitter, Twitch, and 

Discord, because these platforms provided immediate access to an audience of millions of users who 

are already predisposed to be receptive to the game and to become engaged in the play thereof.  The 

ubiquity of these online services makes ARGs the ideal vehicles for Wanless and Berk’s model: the 

content of the game is diffuse and spreads by word-of-mouth, incentivizing existing players to pull in 

as many new players as possible to lighten the load of investigation.  Each of these existing ARG 

players becomes, individually, a potential content dissemination vector.  Furthermore, as my own 

experience with reactive game design has shown, it is possible for ARG players to generate content 

that the game masters feel is superior to their original plan.  When this happens, the ARG masters 

can seamlessly integrate this content into the ARG without the knowledge of the players.  It is not 

inconceivable for a politically motivated “game master” to elevate specific ideologies that emerge 

from within their own playerbase and use those ideas to advance their goals of radicalization.  The 

playerbase becomes more likely to accept these ideas because the ideas were generated from within 

the playerbase itself, as opposed to being handed down from above, as is the case in traditional 

propaganda models.   

The collaborative work of ARG players often takes place on message boards or in private 

chat rooms.  Christian Fuchs notes: “One often hears that social media and the decentralized 

character of the internet overcome hierarchies and foster a participatory culture and democratic 

communication” (Fuchs, 72-73).  Though Fuchs acknowledges that there have been objections to the 

absolute truth of this claim, it is this participatory culture and democratic communication that was on 

display as I observed the playerbases of the ARGs that I have developed.  The vast majority of this 

communication occurred via the Discord chat platform. 

Discord, as a communication platform, is especially notable because although it exists as a 

social network, it differs from other major social network services.  Discord, unlike Facebook, 

Twitter, or other web media firms, does not advertise for services other than its own – it is funded by 

user subscriptions and venture capital, and therefore has a profit orientation that is a step removed 

from the targeted advertising ecosystem of other social networks.  Discord is both a platform for 

communication and a forum for information dissemination, but apart from subscription solicitations, 

the funds from which, support the platform itself, there is no targeted advertising or sales of 

promotional material.  Furthermore, the nature of the system is a double-edged sword with regard to 

ideological dissemination.  Due to the private, decentralized nature of Discord servers – servers can 

be set to private and made invite-only – it has been trivially easy for bad actors to operate on the 

network.  April Glaser reported in 2018 that “Leaders [of the Unite the Right Rally in Charlottesville] 

didn’t do the bulk of their logistical planning in any kind of public forum or open Facebook group. 

They used […] Discord.”  Although Discord purged many accounts associated with the alt-right, she 

writes: 

In the course of an afternoon, I found and joined more than 20 communities on the platform 

that were either directly about Nazism or white supremacy or reveled in sharing anti-Semitic 

and racist memes and imagery. “Discord is always on and always present among these 

groups on the far-right,” says Joan Donovan, the lead researcher on media manipulation at 

the Data & Society Research Institute. “It’s the place where they do most of the organizing of 

doxing and harassment campaigns” (Glaser). 

It can be seen that even in an ecosystem seemingly primed to prohibit the spread of certain types of 

propaganda, the very steps that inhibit that spread can foster the growth of alternate and potentially 

even more malicious ideologies.  

There is not clear agreement among ARG designers as to the degree that they themselves 

are responsible for the rise of the modern conspiracy theory and propaganda methodologies.  

Designer Adrian Hon believes that it is not much. “It is possible that modern disinformation 

people, practitioners, have taken some ideas from ARGs, but I don’t want to give ARGs too 

much credit,” he explains.  “I think it’s more kind of family resemblance than actual direct 

inspiration.  I say that because ARGs have never really been that popular… most people […] 

haven’t played an ARG.  Most of my friends haven’t played ARGs.  I think they use tools in the 

same way, but it probably would have happened anyway, […] it doesn’t keep me up at night 

thinking ‘did I bring about the downfall of western civilization by helping popularize ARG tools’ 

because I think it would have happened anyway, and in a way it did”  (Hon).  Ong’s Hat creator 

Joe Matheny thinks it’s not that simple: “I was seeing [the ARG] being turned into a propaganda 

arm of this kinda alt-right/right-wing conspiracy nut thing that’s been going on for a while, 

which all seems to be in opposition to anybody that opposes Trump” (Matheny).  Matheny 

experienced a “conspiracy nut” scare firsthand in 2000, when, following recieving threatening 

phone calls and having anonymous individuals contact his employer with warnings that he was 

dangerous, he found conspiracy theorists camped out on his front lawn, convinced that the story 

of Ong’s Hat was real (Odelbaum).  Where both agree is that designers need to be increasingly 

vigilant in their creative work so as to not inadvertently create tools for, or worse, promote 

themselves, destructive ideologies. 

We live in a time when world leaders are attempting to use their bully pulpits to produce a 

real-world alternate reality: one that serves their political interests even if it comes at the expense of 

the lives of their citizens.  The 2020 American presidential election put the question of reality itself 

on trial, asking Americans, as they voted, to decide how they define reality: is what the president says 

the truth, even when it seems to fly in the face of their own observations?  At the same time, COVID-

19 has forced much of the world into a quarantine state where increasingly, real-world social 

relationships take shape within the same delivery mechanisms as virtual ones: through the computer 

or phone screen, in text or via video.  At a moment when conspiracy theories like Pizzagate and 

QAnon have become regular fixtures in the news cycle and gaming-related terms such as “NPC” 

(non-player character) have entered the public discourse as insults, it is apparent now more than ever 

that the boundaries between digital spaces and the real world are collapsing.  The advice of Hon and 

Matheny is correct, though not sufficient.  The vigilance of designers as regards their own work 

may help going forward, but cannot address the genie that is already out of the bottle.  There is, 

however, existing research suggesting that ARGs can be used as a tool to counteract the forces 

heretofore described.  Jagoda and others’ educational ARG work, mentioned above, can be taken 

together with the research done by political scientist Josh Lerner about ways in which games can 

be used to promote democracy and democratic participation, as only one example among many.  

Any solution must be twofold, palliative and preventative.  Designers must take steps to address 

potentially harmful practices being utilized right now, while simultaneously taking up the 

challenge to use our tools proactively in new ways that directly combat the root causes of 

antidemocratic urges. Although the question of how to definitively solve viral misinformation is 

beyond the scope of this (and realistically any) paper, there exists a good roadmap available for 

those willing to look.  It is up to those who can read it to help move us toward a better future.   

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Works Cited 

 

American Psychological Association. (2015). Resolution on Violent Video Games.  

http://www.apa.org/about/policy/violent-video-games.aspx 

 
Arendt, Hannah.  The Origins of Totalitarianism.  Cleveland: Meridian Books, 1951.   
 
Berk, Michael and Alicia Wanless.  “Participatory Propaganda: The Engagement of Audiences in  

the Spread of Persuasive Communications.” Social Media & Social Order, Culture 
Conflict 2.0, Oslo, 30 November – 2 December 2017. Unpublished Conference Paper. 
Online, 2020. 

 
Chesterton, G. K.  “The Tremendous Adventures of Major Brown.” Harper’s Weekly vol. 47 July- 

Dec., 1903, pp.2072-2076.  HathiTrust. 

 

 
Fuchs, Christian. “Propaganda 2.0: Herman and Chomsky’s Propaganda Model in the Age of the  

 

Internet, Big Data and Social Media.” The Propaganda Model Today: Filtering 
Perception and Awareness, edited by Joan Pedro-Carañana et al., vol. 8, University of 
Westminster Press, London, 2018. JSTOR, 72. www.jstor.org/stable/j.ctv7h0ts6.8. 
Accessed 22 Feb. 2020.  

 
Gekker, Alex. “Playing with Power : Casual Politicking a New Frame for Political Analysis.”  
The Playful Citizen: Civic Engagement in a Mediatized Culture, edited by René Glas et 
al., vol. 1, Amsterdam University Press, Amsterdam, 2019, pp. 387–419. JSTOR, 
www.jstor.org/stable/j.ctvcmxpds.25. Accessed 17 Feb. 2020.  

 
Glaser, April.  “White Supremacists Still Have a Safe Space Online” Slate.  October 9, 2018.   
Web. https://slate.com/technology/2018/10/discord-safe-space-white-supremacists.html 

 
Heiko, Jethro and Nick Jehlen.  Is This a Coup? December 11, 2020 Update.   

https://isthisacoup.com/ 

 
Hon, Adrian.  "Gamification in a post-truth media - what Alternate Reality Games can teach us  

about QAnon."  Question and Answer session.  StoryFutures Presents, 19 November 
2020. https://www.youtube.com/watch?v=g0t0WI3Se70 

 
Jagoda, Patrick, Melissa Gilliam, Peter McDonald and Christopher Russell.  “Worlding Through  

Play: Alternate Reality Games, Large-Scale Learning and The Source.”  American 
Journal of Play, volume 8, number 1. 74-100. 
https://www.journalofplay.org/sites/www.journalofplay.org/files/pdf-articles/8-1-article-
worlding-through-play.pdf 

 
Kim, Catherine. “Poll: 70 percent of Republicans don’t think the election was free and fair.”  
Politico, 9 November 2020.  https://www.politico.com/news/2020/11/09/republicans-
free-fair-elections-435488 

 

Lerner, Josh A.  Making Democracy Fun: How Game Design Can Empower Citizens and  

Transform Politics.  The MIT Press, 2014.  
 
Matheny, Joseph.  Personal interview.  29 September 2020.  
 
Manjoo, Farhad.  “A.I.: Unravelling the Mysteries.”  Wired, June 28, 2001.   

https://www.wired.com/2001/06/a-i-unraveling-the-mysteries/?currentPage=all. 
 

McHugh, Maureen.  Personal interview.  14 May 2020. 
 
Oelbaum, Jed.  “Ong's Hat: The Early Internet Conspiracy Game That Got Too Real.”  Gizmodo,  

21 February 2019.  https://gizmodo.com/ongs-hat-the-early-internet-conspiracy-game-
that-got-t-1832229488 
 

Stewart, Sean.  “Collaborating with the Audience: Alternate Reality Games” 2006.  

http://www.seanstewart.org/collaborating-with-the-audience-alternate-reality-games/. 

 
Waltman, Michael S. “Teaching Hate: The Role of Internet Visual Imagery in the Radicalization  

of White Ethno-Terrorists in the United States.” Visual Propaganda and Extremism in 
the Online Environment, edited by Carol K. Winkler and Cori E. Dauber, Strategic 
Studies Institute, US Army War College, 2014, pp. 83–104, 
www.jstor.org/stable/resrep12132.7.  

 

 

 

